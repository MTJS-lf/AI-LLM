task_name: general
model_name: qwen
model_args:
  model_name_or_path: /mnt/data1/AIModel/qwen/Qwen1.5-0.5B
  model_type: None
  torch_dtype: bfloat16
  cache_dir: None 

data_args:
  train_path: /mnt/data1/Data/SFT/firefly/train
  eval_path: /mnt/data1/Data/SFT/firefly/test
  train_group_size: 10
  query_max_len: 32
  passage_max_len: 128
  query_instruction_for_retrieval: None
  passage_instruction_for_retrieval: None

max_length: 1024

train_args:
  seed: 1234
  evaluation_strategy: "steps"
  num_train_epochs: 1
  save_total_limit: 2
  logging_steps: 10
  eval_steps: 20
  per_device_train_batch_size: 40
  gradient_accumulation_steps: 4
  per_device_eval_batch_size: 16
  learning_rate: 8.0e-05
  weight_decay: 0.00001
  warmup_ratio: 0.05
  lr_scheduler_type: "cosine"
  report_to: tensorboard
  normlized: true 
  bf16: true
  gradient_checkpointing: true
  output_dir: models
  overwrite_output_dir: true
  deepspeed: deepspeed_config.json
  lora_config: lora_config.json
  use_lora: true
