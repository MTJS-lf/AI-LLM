task_name: general
model_name: bge
model_args:
  model_name_or_path: /mnt/data1/AIModel/chinese-roberta-wwm-ext/
  model_type: None
  torch_dtype: float32
  cache_dir: None 
  use_lstm: false
  use_crf: true
  model_max_length: 128

data_args:
  train_path: /home/liufeng/work/project/AI-LLM/product/ner_pipeline/test_ner/ner/
  eval_path: /home/liufeng/work/project/AI-LLM/product/ner_pipeline/test_ner/ner/

train_args:
  seed: 1234
  evaluation_strategy: "steps"
  num_train_epochs: 50
  save_total_limit: 2
  logging_steps: 2
  eval_steps: 100
  max_steps: 2
  per_device_train_batch_size: 64
  gradient_accumulation_steps: 3
  per_device_eval_batch_size: 3
  learning_rate: 8.0e-05
  weight_decay: 0.00001
  warmup_ratio: 0.05
  lr_scheduler_type: "cosine"
  report_to: tensorboard
  gradient_checkpointing: true
  output_dir: models
  overwrite_output_dir: true
  export_onnx: true
  export_path: model_onnx
  save_safetensors: false
